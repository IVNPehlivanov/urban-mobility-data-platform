{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Config stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from xmlrpc.client import DateTime\n",
    "\n",
    "import ConnectionConfigKaloyan as cc\n",
    "from delta import DeltaTable\n",
    "cc.setupEnvironment()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T11:33:16.015233Z",
     "start_time": "2025-04-23T11:33:15.931599Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "spark = cc.startLocalCluster(\"FACT_RIDE\")\n",
    "spark.getActiveSession()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T11:33:21.744721Z",
     "start_time": "2025-04-23T11:33:18.309201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1c4ddf43b10>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DJQSI3S:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FACT_RIDE</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fact transformations\n",
    "This notebooks creates the sales fact table from scratch based on the operational source table \"sales\"\n",
    "When creating a fact table always follow the listed steps in order."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 1 READ NECESSARY SOURCE TABLE(S) AND PERFORM TRANSFORMATIONS\n",
    "**When reading from the source table make sure you include all data necessary:**\n",
    "- to calculate the measure values\n",
    "- the source table keys that you have to use to lookup the correct surrogate keys in the dimension tables.\n",
    "\n",
    "**If more than one table is needed to gather the necesary information you can opt for one of two strategies:**\n",
    "- Use a select query when reading from the jdbc source with the spark.read operation. Avoid complex queries because the operational database needs a lot of resources to run those queries.\n",
    "- Perform a spark.read operation for each table separately and join the tables within Spark. The joins will take place on the cluster instead of the database. You limit the database recources used, but there can be a significant overhead of unnecessary data tranferred to the cluster.\n",
    "\n",
    "\n",
    "In this case we just rename Amount and create a default count_mv column.\n",
    "The transformations are minimal. In reality, transformations can be far more complex. If so, it can be advisable to work out the transforms in more then one step.*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cc.set_connectionProfile(\"default\")\n",
    "ride_src_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\",\"rides\").option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"rideid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 1000) \\\n",
    "    .load()\n",
    "\n",
    "subscriptions_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\",\"subscriptions\").option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"subscriptionid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 1000) \\\n",
    "    .load()\n",
    "\n",
    "vehicles_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\",\"vehicles\").option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"vehicleid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 1000) \\\n",
    "    .load()\n",
    "\n",
    "bikelots_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\",\"bikelots\").option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"bikelotid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 1000) \\\n",
    "    .load()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# weather_df = spark.read.json(r'C:\\Users\\kkiva\\data4_project_group5\\examples\\weather\\*.json')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T11:33:30.964787Z",
     "start_time": "2025-04-23T11:33:27.470161Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T11:33:34.680875Z",
     "start_time": "2025-04-23T11:33:34.655466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType, ArrayType, DateType\n",
    "\n",
    "# Define the schema for the JSON structure based on the provided response\n",
    "weather_schema = StructType([\n",
    "    StructField(\"zipCode\", StringType(), True),\n",
    "    StructField(\"coord\", StructType([\n",
    "        StructField(\"lon\", FloatType(), True),\n",
    "        StructField(\"lat\", FloatType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"weather\", ArrayType(StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"main\", StringType(), True),\n",
    "        StructField(\"description\", StringType(), True),\n",
    "        StructField(\"icon\", StringType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"base\", StringType(), True),\n",
    "    StructField(\"main\", StructType([\n",
    "        StructField(\"temp\", FloatType(), True),\n",
    "        StructField(\"feels_like\", FloatType(), True),\n",
    "        StructField(\"temp_min\", FloatType(), True),\n",
    "        StructField(\"temp_max\", FloatType(), True),\n",
    "        StructField(\"pressure\", IntegerType(), True),\n",
    "        StructField(\"humidity\", IntegerType(), True),\n",
    "        StructField(\"sea_level\", IntegerType(), True),\n",
    "        StructField(\"grnd_level\", IntegerType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"visibility\", IntegerType(), True),\n",
    "    StructField(\"wind\", StructType([\n",
    "        StructField(\"speed\", FloatType(), True),\n",
    "        StructField(\"deg\", IntegerType(), True),\n",
    "        StructField(\"gust\", FloatType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"rain\", StructType([\n",
    "        StructField(\"1h\", FloatType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"clouds\", StructType([\n",
    "        StructField(\"all\", IntegerType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"dt\", IntegerType(), True),\n",
    "    StructField(\"api_current_time\", StringType(), True),\n",
    "    StructField(\"sys\", StructType([\n",
    "        StructField(\"type\", IntegerType(), True),\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"country\", StringType(), True),\n",
    "        StructField(\"sunrise\", IntegerType(), True),\n",
    "        StructField(\"sunset\", IntegerType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"timezone\", IntegerType(), True),\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"cod\", IntegerType(), True)\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T16:34:33.811660Z",
     "start_time": "2025-03-29T16:34:33.790039Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StructType' object has no attribute 'createOrReplaceTempView'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mweather_schema\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreateOrReplaceTempView\u001B[49m(\u001B[33m\"\u001B[39m\u001B[33mweatherdimx\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mAttributeError\u001B[39m: 'StructType' object has no attribute 'createOrReplaceTempView'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T11:33:46.459003Z",
     "start_time": "2025-04-23T11:33:42.224120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weather_df = spark.read.option(\"multiline\", \"true\").schema(weather_schema).json(\"weather/*.json\")\n",
    "weather_df.printSchema()\n",
    "weather_df.show(5, truncate=False)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- zipCode: string (nullable = true)\n",
      " |-- coord: struct (nullable = true)\n",
      " |    |-- lon: float (nullable = true)\n",
      " |    |-- lat: float (nullable = true)\n",
      " |-- weather: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: integer (nullable = true)\n",
      " |    |    |-- main: string (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- icon: string (nullable = true)\n",
      " |-- base: string (nullable = true)\n",
      " |-- main: struct (nullable = true)\n",
      " |    |-- temp: float (nullable = true)\n",
      " |    |-- feels_like: float (nullable = true)\n",
      " |    |-- temp_min: float (nullable = true)\n",
      " |    |-- temp_max: float (nullable = true)\n",
      " |    |-- pressure: integer (nullable = true)\n",
      " |    |-- humidity: integer (nullable = true)\n",
      " |    |-- sea_level: integer (nullable = true)\n",
      " |    |-- grnd_level: integer (nullable = true)\n",
      " |-- visibility: integer (nullable = true)\n",
      " |-- wind: struct (nullable = true)\n",
      " |    |-- speed: float (nullable = true)\n",
      " |    |-- deg: integer (nullable = true)\n",
      " |    |-- gust: float (nullable = true)\n",
      " |-- rain: struct (nullable = true)\n",
      " |    |-- 1h: float (nullable = true)\n",
      " |-- clouds: struct (nullable = true)\n",
      " |    |-- all: integer (nullable = true)\n",
      " |-- dt: integer (nullable = true)\n",
      " |-- api_current_time: string (nullable = true)\n",
      " |-- sys: struct (nullable = true)\n",
      " |    |-- type: integer (nullable = true)\n",
      " |    |-- id: integer (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- sunrise: integer (nullable = true)\n",
      " |    |-- sunset: integer (nullable = true)\n",
      " |-- timezone: integer (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- cod: integer (nullable = true)\n",
      "\n",
      "+-------+------------------+------------------------------------+--------+---------------------------------------------+----------+-----------------+-----+------+----------+----------------+----------------------------------------+--------+------+-----+---+\n",
      "|zipCode|coord             |weather                             |base    |main                                         |visibility|wind             |rain |clouds|dt        |api_current_time|sys                                     |timezone|id    |name |cod|\n",
      "+-------+------------------+------------------------------------+--------+---------------------------------------------+----------+-----------------+-----+------+----------+----------------+----------------------------------------+--------+------+-----+---+\n",
      "|2018   |{4.42545, 51.2037}|[{3, Neutral, neutral weather, 03d}]|stations|{12.6, 12.6, 11.6, 14.1, 1015, 50, 1015, 933}|10000     |{12.2, 109, 12.7}|{0.0}|{0}   |1742295600|2025-04-23T11:00|{2, 2075663, BE, 1742284800, 1742328000}|3600    |201800|Zocca|200|\n",
      "|2018   |{4.42545, 51.2037}|[{3, Neutral, neutral weather, 03d}]|stations|{12.6, 12.6, 11.6, 14.1, 1015, 50, 1015, 933}|10000     |{12.2, 109, 12.7}|{0.0}|{0}   |1742299200|2025-04-23T11:00|{2, 2075663, BE, 1742288400, 1742331600}|3600    |201800|Zocca|200|\n",
      "|2018   |{4.42545, 51.2037}|[{3, Neutral, neutral weather, 03d}]|stations|{12.6, 12.6, 11.6, 14.1, 1015, 50, 1015, 933}|10000     |{12.2, 109, 12.7}|{0.0}|{0}   |1742302800|2025-04-23T11:00|{2, 2075663, BE, 1742292000, 1742335200}|3600    |201800|Zocca|200|\n",
      "|2020   |{4.39731, 51.1894}|[{3, Neutral, neutral weather, 03d}]|stations|{12.6, 12.6, 11.6, 14.1, 1015, 50, 1015, 933}|10000     |{12.6, 110, 13.1}|{0.0}|{0}   |1742295600|2025-04-23T11:00|{2, 2075663, BE, 1742284800, 1742328000}|3600    |202000|Zocca|200|\n",
      "|2020   |{4.39731, 51.1894}|[{3, Neutral, neutral weather, 03d}]|stations|{12.6, 12.6, 11.6, 14.1, 1015, 50, 1015, 933}|10000     |{12.6, 110, 13.1}|{0.0}|{0}   |1742299200|2025-04-23T11:00|{2, 2075663, BE, 1742288400, 1742331600}|3600    |202000|Zocca|200|\n",
      "+-------+------------------+------------------------------------+--------+---------------------------------------------+----------+-----------------+-----+------+----------+----------------+----------------------------------------+--------+------+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 2 MAKE DIMENSION TABLES AVAILABLE AS VIEWS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dim_date = spark.read.format(\"delta\").load(\"spark-warehouse/dimdate\")\n",
    "dim_vehicle = spark.read.format(\"delta\").load(\"spark-warehouse/dimvehicle\")\n",
    "dim_user = spark.read.format(\"delta\").load(\"spark-warehouse/dimuser\")\n",
    "dim_weather = spark.read.format(\"delta\").load(\"spark-warehouse/dimweather\")\n",
    "dim_lock = spark.read.format(\"delta\").load(\"spark-warehouse/dimlock\")\n",
    "\n",
    "dim_date.createOrReplaceTempView(\"dimDate\")\n",
    "dim_user.createOrReplaceTempView(\"dimUser\")\n",
    "dim_vehicle.createOrReplaceTempView(\"dimVehicle\")\n",
    "dim_weather.createOrReplaceTempView(\"dimWeather\")\n",
    "dim_lock.createOrReplaceTempView(\"dimLock\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T11:33:55.392281Z",
     "start_time": "2025-04-23T11:33:53.369149Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o294.load.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 79) (DESKTOP-DJQSI3S executor driver): org.apache.spark.SparkException: Encountered error while reading file file:///C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000000.json. Details:\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFilesError(QueryExecutionErrors.scala:864)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:293)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000000.json at 0 exp: -559546752 got: 1470641045\r\n\tat org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)\r\n\tat java.base/java.io.DataInputStream.read(DataInputStream.java:151)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\r\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)\r\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:158)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:198)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:67)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\t... 22 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4334)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3575)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4324)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3575)\r\n\tat org.apache.spark.sql.delta.Snapshot.protocolMetadataAndICTReconstruction(Snapshot.scala:309)\r\n\tat org.apache.spark.sql.delta.Snapshot._reconstructedProtocolMetadataAndICT$lzycompute(Snapshot.scala:203)\r\n\tat org.apache.spark.sql.delta.Snapshot._reconstructedProtocolMetadataAndICT(Snapshot.scala:196)\r\n\tat org.apache.spark.sql.delta.Snapshot.metadata(Snapshot.scala:278)\r\n\tat org.apache.spark.sql.delta.managedcommit.CommitOwnerProvider$.getTableCommitOwner(CommitOwnerClient.scala:212)\r\n\tat org.apache.spark.sql.delta.Snapshot.initializeTableCommitOwner(Snapshot.scala:237)\r\n\tat org.apache.spark.sql.delta.Snapshot.<init>(Snapshot.scala:235)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$createSnapshot$2(SnapshotManagement.scala:634)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment(SnapshotManagement.scala:796)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment$(SnapshotManagement.scala:782)\r\n\tat org.apache.spark.sql.delta.DeltaLog.createSnapshotFromGivenOrEquivalentLogSegment(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshot(SnapshotManagement.scala:627)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshot$(SnapshotManagement.scala:618)\r\n\tat org.apache.spark.sql.delta.DeltaLog.createSnapshot(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotForLogSegmentInternal$1(SnapshotManagement.scala:1043)\r\n\tat scala.Option.map(Option.scala:230)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal(SnapshotManagement.scala:1036)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal$(SnapshotManagement.scala:1031)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotForLogSegmentInternal(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot(SnapshotManagement.scala:1012)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot$(SnapshotManagement.scala:1003)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getUpdatedSnapshot(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$2(SnapshotManagement.scala:583)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.DeltaLog.recordFrameProfile(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$1(SnapshotManagement.scala:573)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly(SnapshotManagement.scala:78)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly$(SnapshotManagement.scala:75)\r\n\tat org.apache.spark.sql.delta.DeltaLog.withSnapshotLockInterruptibly(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit(SnapshotManagement.scala:573)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit$(SnapshotManagement.scala:572)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotAtInit(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$init$(SnapshotManagement.scala:69)\r\n\tat org.apache.spark.sql.delta.DeltaLog.<init>(DeltaLog.scala:80)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$4(DeltaLog.scala:853)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$3(DeltaLog.scala:848)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordFrameProfile(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:136)\r\n\tat com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)\r\n\tat com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordOperation(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:135)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:125)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:115)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordDeltaOperation(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.createDeltaLog$1(DeltaLog.scala:847)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$5(DeltaLog.scala:866)\r\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4792)\r\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)\r\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)\r\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)\r\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2257)\r\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:4000)\r\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4789)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.getDeltaLogFromCache$1(DeltaLog.scala:865)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.apply(DeltaLog.scala:875)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.forTable(DeltaLog.scala:751)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$deltaLog$1(DeltaTableV2.scala:92)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog$lzycompute(DeltaTableV2.scala:92)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog(DeltaTableV2.scala:90)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$4(DeltaTableV2.scala:145)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$1(DeltaTableV2.scala:145)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot$lzycompute(DeltaTableV2.scala:144)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot(DeltaTableV2.scala:124)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation$lzycompute(DeltaTableV2.scala:236)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation(DeltaTableV2.scala:234)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.$anonfun$createRelation$5(DeltaDataSource.scala:250)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.recordFrameProfile(DeltaDataSource.scala:49)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:209)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.spark.SparkException: Encountered error while reading file file:///C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000000.json. Details:\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFilesError(QueryExecutionErrors.scala:864)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:293)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000000.json at 0 exp: -559546752 got: 1470641045\r\n\tat org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)\r\n\tat java.base/java.io.DataInputStream.read(DataInputStream.java:151)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\r\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)\r\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:158)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:198)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:67)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\t... 22 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPy4JJavaError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m dim_date = \u001B[43mspark\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m.\u001B[49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdelta\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mspark-warehouse/dimdate\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m dim_vehicle = spark.read.format(\u001B[33m\"\u001B[39m\u001B[33mdelta\u001B[39m\u001B[33m\"\u001B[39m).load(\u001B[33m\"\u001B[39m\u001B[33mspark-warehouse/dimvehicle\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      3\u001B[39m dim_user = spark.read.format(\u001B[33m\"\u001B[39m\u001B[33mdelta\u001B[39m\u001B[33m\"\u001B[39m).load(\u001B[33m\"\u001B[39m\u001B[33mspark-warehouse/dimuser\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:307\u001B[39m, in \u001B[36mDataFrameReader.load\u001B[39m\u001B[34m(self, path, format, schema, **options)\u001B[39m\n\u001B[32m    305\u001B[39m \u001B[38;5;28mself\u001B[39m.options(**options)\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m307\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_jreader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    308\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    309\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(path) != \u001B[38;5;28mlist\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001B[39m, in \u001B[36mJavaMember.__call__\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m   1316\u001B[39m command = proto.CALL_COMMAND_NAME +\\\n\u001B[32m   1317\u001B[39m     \u001B[38;5;28mself\u001B[39m.command_header +\\\n\u001B[32m   1318\u001B[39m     args_command +\\\n\u001B[32m   1319\u001B[39m     proto.END_COMMAND_PART\n\u001B[32m   1321\u001B[39m answer = \u001B[38;5;28mself\u001B[39m.gateway_client.send_command(command)\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m return_value = \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1323\u001B[39m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1325\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[32m   1326\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[33m\"\u001B[39m\u001B[33m_detach\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001B[39m, in \u001B[36mcapture_sql_exception.<locals>.deco\u001B[39m\u001B[34m(*a, **kw)\u001B[39m\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdeco\u001B[39m(*a: Any, **kw: Any) -> Any:\n\u001B[32m    178\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    180\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    181\u001B[39m         converted = convert_exception(e.java_exception)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\py4j\\protocol.py:326\u001B[39m, in \u001B[36mget_return_value\u001B[39m\u001B[34m(answer, gateway_client, target_id, name)\u001B[39m\n\u001B[32m    324\u001B[39m value = OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[32m2\u001B[39m:], gateway_client)\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[32m1\u001B[39m] == REFERENCE_TYPE:\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[32m    327\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.\n\u001B[32m    328\u001B[39m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m, name), value)\n\u001B[32m    329\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    330\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[32m    331\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.\n\u001B[32m    332\u001B[39m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m, name, value))\n",
      "\u001B[31mPy4JJavaError\u001B[39m: An error occurred while calling o294.load.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 79) (DESKTOP-DJQSI3S executor driver): org.apache.spark.SparkException: Encountered error while reading file file:///C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000000.json. Details:\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFilesError(QueryExecutionErrors.scala:864)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:293)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000000.json at 0 exp: -559546752 got: 1470641045\r\n\tat org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)\r\n\tat java.base/java.io.DataInputStream.read(DataInputStream.java:151)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\r\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)\r\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:158)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:198)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:67)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\t... 22 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4334)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3575)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4324)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3575)\r\n\tat org.apache.spark.sql.delta.Snapshot.protocolMetadataAndICTReconstruction(Snapshot.scala:309)\r\n\tat org.apache.spark.sql.delta.Snapshot._reconstructedProtocolMetadataAndICT$lzycompute(Snapshot.scala:203)\r\n\tat org.apache.spark.sql.delta.Snapshot._reconstructedProtocolMetadataAndICT(Snapshot.scala:196)\r\n\tat org.apache.spark.sql.delta.Snapshot.metadata(Snapshot.scala:278)\r\n\tat org.apache.spark.sql.delta.managedcommit.CommitOwnerProvider$.getTableCommitOwner(CommitOwnerClient.scala:212)\r\n\tat org.apache.spark.sql.delta.Snapshot.initializeTableCommitOwner(Snapshot.scala:237)\r\n\tat org.apache.spark.sql.delta.Snapshot.<init>(Snapshot.scala:235)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$createSnapshot$2(SnapshotManagement.scala:634)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment(SnapshotManagement.scala:796)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment$(SnapshotManagement.scala:782)\r\n\tat org.apache.spark.sql.delta.DeltaLog.createSnapshotFromGivenOrEquivalentLogSegment(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshot(SnapshotManagement.scala:627)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshot$(SnapshotManagement.scala:618)\r\n\tat org.apache.spark.sql.delta.DeltaLog.createSnapshot(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotForLogSegmentInternal$1(SnapshotManagement.scala:1043)\r\n\tat scala.Option.map(Option.scala:230)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal(SnapshotManagement.scala:1036)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal$(SnapshotManagement.scala:1031)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotForLogSegmentInternal(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot(SnapshotManagement.scala:1012)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot$(SnapshotManagement.scala:1003)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getUpdatedSnapshot(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$2(SnapshotManagement.scala:583)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.DeltaLog.recordFrameProfile(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$1(SnapshotManagement.scala:573)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly(SnapshotManagement.scala:78)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly$(SnapshotManagement.scala:75)\r\n\tat org.apache.spark.sql.delta.DeltaLog.withSnapshotLockInterruptibly(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit(SnapshotManagement.scala:573)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit$(SnapshotManagement.scala:572)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotAtInit(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$init$(SnapshotManagement.scala:69)\r\n\tat org.apache.spark.sql.delta.DeltaLog.<init>(DeltaLog.scala:80)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$4(DeltaLog.scala:853)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$3(DeltaLog.scala:848)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordFrameProfile(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:136)\r\n\tat com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)\r\n\tat com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordOperation(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:135)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:125)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:115)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordDeltaOperation(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.createDeltaLog$1(DeltaLog.scala:847)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$5(DeltaLog.scala:866)\r\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4792)\r\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)\r\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)\r\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)\r\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2257)\r\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:4000)\r\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4789)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.getDeltaLogFromCache$1(DeltaLog.scala:865)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.apply(DeltaLog.scala:875)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.forTable(DeltaLog.scala:751)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$deltaLog$1(DeltaTableV2.scala:92)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog$lzycompute(DeltaTableV2.scala:92)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog(DeltaTableV2.scala:90)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$4(DeltaTableV2.scala:145)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$1(DeltaTableV2.scala:145)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot$lzycompute(DeltaTableV2.scala:144)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot(DeltaTableV2.scala:124)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation$lzycompute(DeltaTableV2.scala:236)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation(DeltaTableV2.scala:234)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.$anonfun$createRelation$5(DeltaDataSource.scala:250)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.recordFrameProfile(DeltaDataSource.scala:49)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:209)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.spark.SparkException: Encountered error while reading file file:///C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000000.json. Details:\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFilesError(QueryExecutionErrors.scala:864)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:293)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000000.json at 0 exp: -559546752 got: 1470641045\r\n\tat org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)\r\n\tat java.base/java.io.DataInputStream.read(DataInputStream.java:151)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\r\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)\r\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:158)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:198)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:67)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\t... 22 more\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:35:08.850071Z",
     "start_time": "2025-04-23T08:35:05.094414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xxd = spark.sql(\"\"\"\n",
    "SELECT *  FROM dimVehicle;\n",
    "\"\"\")\n",
    "xxd.show()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------------------+\n",
      "|vehicleid|biketypeid|biketypedescription|\n",
      "+---------+----------+-------------------+\n",
      "|     NULL|         1|          Velo Bike|\n",
      "|     NULL|         2|        Velo E-Bike|\n",
      "|     NULL|         3|               Step|\n",
      "|     NULL|         4|            Scooter|\n",
      "+---------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 3 Build the fact table\n",
    "\n",
    "Within the creation of a fact table always perform these two tasks:\n",
    "1.   Include the measures of the fact\n",
    "2. Use the dimension tables to look up the surrogate keys that correspond with the natural key value. In case of SCD2 dimension use the scd_start en scd_end to find the correct version of the data in the dimension\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:22:34.997840Z",
     "start_time": "2025-04-23T09:22:34.963042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "import math\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    if None in (lat1, lon1, lat2, lon2):  # Handle NULL values safely\n",
    "        return None  \n",
    "    R = 6371  # Radius of Earth in km\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Register the UDF in Spark SQL\n",
    "haversine_udf = udf(haversine_km, DoubleType())\n",
    "spark.udf.register(\"haversine_km\", haversine_udf)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/23 11:22:34 WARN SimpleFunctionRegistry: The function haversine_km replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.udf.UserDefinedFunction at 0x1127b2f10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "ride_src_df.createOrReplaceTempView(\"rides_source\")\n",
    "subscriptions_df.createOrReplaceTempView(\"subscriptions_source\")\n",
    "\n",
    "# Create temp views for the required dataframes\n",
    "weather_df.createOrReplaceTempView(\"weather_data\")\n",
    "\n",
    "vehicles_df.createOrReplaceTempView(\"vehicle_data\")\n",
    "bikelots_df.createOrReplaceTempView(\"bikelots_data\")\n",
    "\n",
    "ridesFactFromSource = spark.sql(\"\"\"\n",
    "    SELECT src.rideid AS ride_id, \n",
    "           du.userSK AS user_sk, \n",
    "           src.startlockid AS start_lock_id, \n",
    "           src.endlockid AS end_lock_id, \n",
    "           dd.date_sk AS date_sk, \n",
    "           dv.biketypeid AS vehicle_id, \n",
    "              CASE \n",
    "           WHEN unix_timestamp(src.endtime) > unix_timestamp(src.starttime) \n",
    "           THEN ROUND((unix_timestamp(src.endtime) - unix_timestamp(src.starttime)) / 60, 2)\n",
    "           ELSE 0  \n",
    "           END AS ride_duration, \n",
    "           Round(haversine_km(\n",
    "               CAST(SPLIT(REPLACE(dl_start.gpscoord, '(', ''), ',')[0] AS DOUBLE),\n",
    "               CAST(SPLIT(REPLACE(REPLACE(dl_start.gpscoord, ')', ''), '(', ''), ',')[1] AS DOUBLE),\n",
    "               CAST(SPLIT(REPLACE(dl_end.gpscoord, '(', ''), ',')[0] AS DOUBLE),\n",
    "               CAST(SPLIT(REPLACE(REPLACE(dl_end.gpscoord, ')', ''), '(', ''), ',')[1] AS DOUBLE)\n",
    "           ),2) AS distance_km,\n",
    "           MIN(dw.weather_id) AS weather_id,  \n",
    "           md5(concat(src.rideid, du.userSK, src.startlockid, src.endlockid, dd.date_sk, dv.biketypeid)) AS md5 \n",
    "    FROM rides_source AS src \n",
    "    LEFT OUTER JOIN subscriptions_source AS sub ON src.subscriptionid = sub.subscriptionid \n",
    "    LEFT OUTER JOIN dimUser AS du ON sub.userid = du.userid \n",
    "    LEFT OUTER JOIN dimLock AS dl_start ON src.startlockid = dl_start.lockid  \n",
    "    LEFT OUTER JOIN dimLock AS dl_end ON src.endlockid = dl_end.lockid  \n",
    "    LEFT OUTER JOIN dimDate AS dd ON DATE(src.starttime) = dd.date \n",
    "    LEFT OUTER JOIN vehicle_data AS vd ON src.vehicleid = vd.vehicleid\n",
    "    LEFT OUTER JOIN bikelots_data AS bl ON vd.bikelotid = bl.bikelotid\n",
    "    LEFT OUTER JOIN dimVehicle as dv ON bl.biketypeid = dv.biketypeid\n",
    "    LEFT OUTER JOIN weather_data AS wd ON dl_start.zipcode = wd.zipcode\n",
    "    LEFT OUTER JOIN dimWeather AS dw ON wd.weather[0].main = dw.weather_condition\n",
    "    GROUP BY src.rideid, du.userSK, src.startlockid, src.endlockid, dd.date_sk, dv.biketypeid,\n",
    "             src.starttime, src.endtime, dl_start.gpscoord, dl_end.gpscoord\n",
    "\"\"\")\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:25:47.779114Z",
     "start_time": "2025-04-23T09:25:47.588850Z"
    }
   },
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:23:57.192738Z",
     "start_time": "2025-04-23T09:23:57.109305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ride_src_df.createOrReplaceTempView(\"rides_source\")\n",
    "subscriptions_df.createOrReplaceTempView(\"subscriptions_source\")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:19:04.627623Z",
     "start_time": "2025-04-23T09:19:04.018004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trying to fix null subscription ids \n",
    "xd = spark.sql(\"\"\"\n",
    "SELECT * from rides_source\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "xd.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-----------------+-------------------+-------------------+---------+--------------+-----------+---------+\n",
      "|rideid|       startpoint|         endpoint|          starttime|            endtime|vehicleid|subscriptionid|startlockid|endlockid|\n",
      "+------+-----------------+-----------------+-------------------+-------------------+---------+--------------+-----------+---------+\n",
      "|     1|(51.2083,4.44595)|(51.1938,4.40228)|2015-09-22 00:00:00|2012-09-22 00:00:00|      844|         13296|       4849|     3188|\n",
      "|     2|(51.2174,4.41597)|(51.2188,4.40935)|2015-09-22 00:00:00|2012-09-22 00:00:00|     4545|         45924|       NULL|     NULL|\n",
      "|     3|(51.2088,4.40834)|(51.2077,4.39846)|2015-09-22 00:00:00|2012-09-22 00:00:00|     3419|         25722|       2046|     1951|\n",
      "|     4|(51.2023,4.41208)|(51.2119,4.39894)|2015-09-22 00:00:00|2012-09-22 00:00:00|     1208|         31000|       1821|     2186|\n",
      "|     5|(51.1888,4.45039)|(51.2221,4.40467)|2015-09-22 00:00:00|2012-09-22 00:00:00|     5536|         59732|       6382|     2700|\n",
      "|     6|(51.2159,4.41073)|(51.2191,4.41596)|2015-09-22 00:00:00|2012-09-22 00:00:00|     6336|          NULL|       NULL|     NULL|\n",
      "|     7|(51.2038,4.42077)|(51.2055,4.39933)|2015-09-22 00:00:00|2012-09-22 00:00:00|     4045|         31055|       1388|     3401|\n",
      "|     8| (51.2191,4.3949)|  (51.2281,4.409)|2015-09-22 00:00:00|2012-09-22 00:00:00|     2015|         65164|       2572|       13|\n",
      "|     9|(51.2182,4.41238)| (51.209,4.43266)|2015-09-22 00:00:00|2012-09-22 00:00:00|     5298|         71164|         50|     2067|\n",
      "|    10|(51.2196,4.41724)|(51.2143,4.41316)|2015-09-22 00:00:00|2012-09-22 00:00:00|     6332|         68426|       NULL|     NULL|\n",
      "|    11|(51.2179,4.41777)| (51.211,4.40724)|2015-09-22 00:00:00|2012-09-22 00:00:00|     1400|           999|        985|     2148|\n",
      "|    12|(51.2088,4.40834)|(51.2145,4.44373)|2015-09-22 00:00:00|2012-09-22 00:00:00|      957|         59847|       2039|     3038|\n",
      "|    13|(51.1744,4.40334)|(51.2228,4.42426)|2015-09-22 00:00:00|2012-09-22 00:00:00|     5413|          5045|       5619|     2717|\n",
      "|    14|   (51.25,4.4209)|   (51.25,4.4209)|2015-09-22 00:00:00|2012-09-22 00:00:00|     2658|         65816|       3531|     3554|\n",
      "|    15|(51.2083,4.44595)|(51.1938,4.40228)|2019-09-22 08:46:43|2019-09-22 09:01:36|      844|         13296|       4849|     3188|\n",
      "|    16|(51.2174,4.41597)|(51.2188,4.40935)|2019-09-22 08:19:51|2019-09-22 08:21:55|     4545|         45924|       NULL|     NULL|\n",
      "|    17|(51.2088,4.40834)|(51.2077,4.39846)|2019-09-22 08:27:38|2019-09-22 08:30:25|     3419|         25722|       2046|     1951|\n",
      "|    18|(51.2023,4.41208)|(51.2119,4.39894)|2019-09-22 08:41:48|2019-09-22 08:46:52|     1208|         31000|       1821|     2186|\n",
      "|    19|(51.1888,4.45039)|(51.2221,4.40467)|2019-09-22 08:50:08|2019-09-22 09:09:02|     5536|         59732|       6382|     2700|\n",
      "|    20|(51.2159,4.41073)|(51.2191,4.41596)|2019-09-22 08:29:42|2019-09-22 08:31:40|     6336|          NULL|       NULL|     NULL|\n",
      "+------+-----------------+-----------------+-------------------+-------------------+---------+--------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T09:26:23.759838Z",
     "start_time": "2025-04-23T09:25:53.411780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ridesFactFromSource.printSchema()\n",
    "ridesFactFromSource.show(50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ride_id: integer (nullable = true)\n",
      " |-- user_sk: string (nullable = true)\n",
      " |-- start_lock_id: integer (nullable = true)\n",
      " |-- end_lock_id: integer (nullable = true)\n",
      " |-- date_sk: long (nullable = true)\n",
      " |-- vehicle_id: integer (nullable = true)\n",
      " |-- ride_duration: double (nullable = true)\n",
      " |-- distance_km: double (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- md5: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 184:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------+-----------+-------+----------+-------------+-----------+----------+--------------------+\n",
      "|ride_id|             user_sk|start_lock_id|end_lock_id|date_sk|vehicle_id|ride_duration|distance_km|weather_id|                 md5|\n",
      "+-------+--------------------+-------------+-----------+-------+----------+-------------+-----------+----------+--------------------+\n",
      "|     13|d8f685cc-3412-4e0...|         5619|       2717|   2455|         2|          0.0|       5.38|         3|ec253130345dc6c41...|\n",
      "|     50|93e34254-7e69-47f...|         2962|       2973|   3916|         2|         5.23|       0.56|         3|e63cb075e0d01c00f...|\n",
      "|     67|f018bf1b-7ae3-484...|         1494|       5591|   3916|         1|        17.13|       4.46|         3|83caf42c81687b0cc...|\n",
      "|     79|b8f870fe-c89a-4fb...|         3260|       1411|   3916|         1|         13.2|       2.16|         3|3bc9fded18efd494f...|\n",
      "|    108|ea4639ae-6955-40b...|         6314|       4117|   3916|         1|        24.17|       4.64|         3|f1ade98fd45c945ae...|\n",
      "|    111|dfdc54bd-b3d7-46b...|         6570|       2739|   3916|         1|         4.38|       4.19|         3|18644bb43d048196e...|\n",
      "|    124|a7358511-c820-4af...|         3496|       4058|   3916|         1|         7.32|       1.19|         3|95c7d60f5877b308e...|\n",
      "|    135|8bca31e8-1922-4c8...|         2952|       1819|   3916|         1|        11.82|       3.19|         3|9e7c324a4bfe4a804...|\n",
      "|    136|f9ab1f92-794e-4a0...|         7542|        536|   3916|         2|         8.88|       0.77|         3|170bf711dc3010115...|\n",
      "|    206|145583f4-0ecf-42d...|         1445|       5118|   3916|         1|        15.65|       3.96|         3|d79127ae1a16bcaa2...|\n",
      "|    208|9703ba35-fec6-432...|          599|        918|   3916|         1|         8.92|       2.58|         3|6d9135a53dec71e7e...|\n",
      "|    218|eb7681cb-3287-48e...|         6549|       1147|   3916|         2|        11.05|       2.85|         3|d0ad83a1b57a7be97...|\n",
      "|    224|adb277e1-0598-457...|         1999|       3541|   3916|         1|         17.7|       3.99|         3|fb1260978e30b38e0...|\n",
      "|    232|6f564c62-d269-4ed...|          554|       2330|   3916|         1|         6.02|       1.89|         3|a4317a422ca2a91bc...|\n",
      "|    240|c90ccc2b-1b46-47e...|          186|       7267|   3916|         2|        20.97|       5.57|         3|068dec0d6887c6de5...|\n",
      "|      1|63bfe040-f1ff-4bb...|         4849|       3188|   2455|         1|          0.0|       3.49|         3|b8c91a2ea09aa5f7c...|\n",
      "|     18|0553493e-89b1-472...|         1821|       2186|   3916|         1|         5.07|       2.31|         3|2d7c426ea562b1f29...|\n",
      "|     35|d2a13cde-b1c1-481...|         1117|        677|   3916|         1|        10.47|       2.18|         3|785d876c7dc72f167...|\n",
      "|     36|cf9bac83-d8e9-4f8...|         6421|       1208|   3916|         1|        17.77|       5.04|         3|46fec4c82fe6518c8...|\n",
      "|     43|70dfccc4-39e2-41b...|         2507|       2365|   3916|         1|         6.52|       2.29|         3|44c550359cee153ac...|\n",
      "|     76|9031f92d-b6b2-448...|         4181|        979|   3916|         1|         4.82|       3.77|         3|6b5f7d612776f154a...|\n",
      "|    115|b17d099b-5ef7-4d2...|         6256|       4168|   3916|         1|         11.5|       8.04|         3|2ffec2cea6b38b215...|\n",
      "|    144|4a2b3924-7e60-48e...|         4799|       1044|   3916|         2|        16.98|       2.53|         3|9be5256a83e38df6f...|\n",
      "|    160|21581845-e936-463...|         2636|       3830|   3916|         1|        20.12|       2.78|         3|8444b42b778c0c3f7...|\n",
      "|    166|77f8ec56-4cd6-41e...|         2351|       2793|   3916|         1|         7.08|       1.24|         3|b13ac66fa65d86d6c...|\n",
      "|    170|d35fe247-74e7-4fc...|         3005|       2592|   3916|         2|         5.38|       3.35|         3|1658974d1ff2bad6e...|\n",
      "|    202|d6323fe5-63f9-42d...|         2821|       1190|   3916|         1|         8.22|       3.33|         3|0df2df3d7e381e08a...|\n",
      "|    204|f14d0560-32d2-48c...|         4482|       4279|   3916|         1|         1.95|       0.98|         3|129270404fa57ee6b...|\n",
      "|    230|8e13e97c-8658-498...|          723|       1473|   3916|         1|         7.12|       2.05|         3|9d75482a2ef068e30...|\n",
      "|    241|5b1ab9d2-2bdb-43d...|         2795|       4849|   3916|         1|        17.07|       3.47|         3|9a8ddcb876097288e...|\n",
      "|      7|a7551bdf-1268-463...|         1388|       3401|   2455|         1|          0.0|       7.07|         3|31690a4f5129c341b...|\n",
      "|     32|aa9ae7cb-5ee0-4a4...|         1056|        792|   3916|         1|          5.5|       2.23|         3|cfae1c133cb4c610d...|\n",
      "|     45|0c8a7a74-f6f2-4c3...|          615|       4172|   3916|         1|         4.48|       4.84|         3|7b55aee1fa7a9860f...|\n",
      "|     57|9a2bae01-ebf0-400...|          513|       2242|   3916|         1|        14.63|       2.47|         3|9f5de7d358200a1d6...|\n",
      "|     63|54970d35-83b6-4cd...|         2432|       2137|   3916|         1|         2.98|       2.32|         3|d5379b19bcec67d2b...|\n",
      "|    131|54dd2425-157e-43b...|         5099|       2466|   3916|         1|         8.18|       3.11|         3|3d9e6c90eba351995...|\n",
      "|    149|6820395d-0941-4b8...|         4076|       2430|   3916|         1|          4.5|       2.01|         3|7240a6e147e805f0b...|\n",
      "|    186|76f57250-8444-402...|         2788|       2626|   3916|         1|          7.3|       1.46|         3|ca6c4fdf4e891294e...|\n",
      "|    189|e3c0ff0b-e242-4c2...|         1421|       4066|   3916|         1|         10.0|       3.28|         3|55e6a82834b31514e...|\n",
      "|    191|c3e991ec-77eb-48a...|         3251|       2428|   3916|         1|          7.0|       1.75|         3|fd1e59406442168d4...|\n",
      "|     53|ca4e201b-7e1d-42f...|         4917|       1613|   3916|         1|        13.58|       2.59|         3|7cd4c31f30c0d3c5a...|\n",
      "|     70|31bf3b49-035f-438...|         3821|        626|   3916|         1|        18.87|       6.06|         3|7df3bdfd863dcbc3e...|\n",
      "|     80|ad9f11d3-cd7e-48a...|         3253|       5866|   3916|         1|        24.93|       6.75|         3|6a89533863c66103e...|\n",
      "|     99|5d4b48b3-9743-4f4...|         1865|       7530|   3916|         2|         3.08|       3.11|         3|95b61617b3c4cc12d...|\n",
      "|    105|b0b9c47c-0b8c-49f...|         1933|       1983|   3916|         2|          3.4|       0.97|         3|569638d01447f3df7...|\n",
      "|    116|c431774c-7281-482...|         5232|       2884|   3916|         2|        17.12|       5.43|         3|f42cd11d48d02a3f5...|\n",
      "|    127|859286c3-589d-456...|         1193|       1065|   3916|         2|         1.65|       3.09|         3|7d06817a50ffd1c7f...|\n",
      "|    140|36ca2050-338d-473...|         2116|        750|   3916|         1|         6.98|       2.05|         3|2309282e56656c797...|\n",
      "|    158|691e574f-767e-4c0...|         3241|       7111|   3916|         1|         28.0|       4.91|         3|1fb60eb50ead01307...|\n",
      "|    178|8bb908fd-38b0-47d...|         5755|       5653|   3916|         1|         4.88|       1.99|         3|c99c987ed23e51e37...|\n",
      "+-------+--------------------+-------------+-----------+-------+----------+-------------+-----------+----------+--------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial load\n",
    "The first time loading the fact table perform a FULL load. All data is written to the Delta Table.\n",
    "After initial load the code line has to be disabled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "ridesFactFromSource.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"factRides\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T09:05:47.811624Z",
     "start_time": "2025-04-23T08:10:47.999474Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridesFactFromSource' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mridesFactFromSource\u001B[49m.write.format(\u001B[33m\"\u001B[39m\u001B[33mdelta\u001B[39m\u001B[33m\"\u001B[39m).mode(\u001B[33m\"\u001B[39m\u001B[33moverwrite\u001B[39m\u001B[33m\"\u001B[39m).saveAsTable(\u001B[33m\"\u001B[39m\u001B[33mfactRides\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'ridesFactFromSource' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Incremental load\n",
    "When previous runs where performend you can opt for a 'faster' incremental run that only writes away changes. UPDATES and INSERTS are performed in one run.\n",
    "In our solution we use an md5 based on all fields in the source table to detect changes. This is not the most efficient way to detect changes. A better way is to use a timestamp field in the source table and use that to detect changes. This is not implemented in this example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|                0|               0|               0|                0|\n",
      "+-----------------+----------------+----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "dt_factRides = DeltaTable.forPath(spark,\".\\spark-warehouse\\\\factrides\")\n",
    "dt_factRides.toDF().createOrReplaceTempView(\"factRides_current\")\n",
    "#Merge to perform updates (TODO: Implement md5 strategy)\n",
    "\n",
    "result = spark.sql(\"MERGE INTO factRides_current AS target \\\n",
    "      using factRides_new AS source ON target.rideID = source.rideID \\\n",
    "      WHEN MATCHED and source.MD5<>target.MD5 THEN UPDATE SET * \\\n",
    "      WHEN NOT MATCHED THEN INSERT *\")\n",
    "\n",
    "result.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T09:05:47.811792Z",
     "start_time": "2024-09-10T09:49:24.834540600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     999|\n",
      "+--------+\n",
      "\n",
      "+-------+------+--------------------+--------+----------+--------------------+\n",
      "|OrderID|dateSK|          salesrepSK|count_mv|revenue_mv|                 md5|\n",
      "+-------+------+--------------------+--------+----------+--------------------+\n",
      "|      1|   650|b65df3d9-20dc-42d...|       1| 851804379|a237b06f2932af7dd...|\n",
      "+-------+------+--------------------+--------+----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: ALWAYS TEST THE CREATED CODE.\n",
    "# In this example I changed order 498 in the operational database and checked the change after the run.\n",
    "# spark.sql(\"select * from factsales f join dimsalesrep ds on f.salesrepSK = ds.salesrepSK where OrderID = 192  \").show()\n",
    "spark.sql(\"select count(*) from factrides\").show()\n",
    "spark.sql(\"select * from factrides where rideId=1\").show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T09:05:47.811908Z",
     "start_time": "2024-09-10T09:49:36.262239400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking the history of your delta fact table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# The history information is derived from the delta table log files. They contain a lot of information of all the actions performed on the table. In this case it tells us something about de merge operations. You can find statistics about the update and insert counts in the document.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mfact\u001B[49m\u001B[38;5;241m.\u001B[39mhistory()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m,\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'fact' is not defined"
     ]
    }
   ],
   "source": [
    "# The history information is derived from the delta table log files. They contain a lot of information of all the actions performed on the table. In this case it tells us something about de merge operations. You can find statistics about the update and insert counts in the document.\n",
    "\n",
    "fact.history().show(10,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T09:05:47.812019Z",
     "start_time": "2024-09-10T09:49:41.415008600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T09:05:47.812202Z",
     "start_time": "2025-03-19T11:01:55.677763Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
