{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Config stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import ConnectionConfigKaloyan as cc\n",
    "from delta import DeltaTable\n",
    "cc.setupEnvironment()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T12:51:17.261376Z",
     "start_time": "2025-03-19T12:51:16.967264Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "spark = cc.startLocalCluster(\"FACT_RIDE\")\n",
    "spark.getActiveSession()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T12:51:59.468288Z",
     "start_time": "2025-03-19T12:51:18.467941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x14c99773710>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DJQSI3S:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FACT_RIDE</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fact transformations\n",
    "This notebooks creates the sales fact table from scratch based on the operational source table \"sales\"\n",
    "When creating a fact table always follow the listed steps in order."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 1 READ NECESSARY SOURCE TABLE(S) AND PERFORM TRANSFORMATIONS\n",
    "**When reading from the source table make sure you include all data necessary:**\n",
    "- to calculate the measure values\n",
    "- the source table keys that you have to use to lookup the correct surrogate keys in the dimension tables.\n",
    "\n",
    "**If more than one table is needed to gather the necesary information you can opt for one of two strategies:**\n",
    "- Use a select query when reading from the jdbc source with the spark.read operation. Avoid complex queries because the operational database needs a lot of resources to run those queries.\n",
    "- Perform a spark.read operation for each table separately and join the tables within Spark. The joins will take place on the cluster instead of the database. You limit the database recources used, but there can be a significant overhead of unnecessary data tranferred to the cluster.\n",
    "\n",
    "\n",
    "In this case we just rename Amount and create a default count_mv column.\n",
    "The transformations are minimal. In reality, transformations can be far more complex. If so, it can be advisable to work out the transforms in more then one step.*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cc.set_connectionProfile(\"default\")\n",
    "ride_src_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\",\"rides\").option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"rideid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 1000) \\\n",
    "    .load()\n",
    "\n",
    "subscriptions_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\",\"subscriptions\").option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"subscriptionid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 1000) \\\n",
    "    .load()\n",
    "\n",
    "weather_df = spark.read.json(r'C:\\Users\\kkiva\\data4_project_group5\\examples\\weather\\*.json')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T13:10:13.876481Z",
     "start_time": "2025-03-19T13:10:11.791157Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T13:12:04.764261Z",
     "start_time": "2025-03-19T13:12:03.928065Z"
    }
   },
   "cell_type": "code",
   "source": "weather_df.show(20)",
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Since Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count().",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAnalysisException\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mweather_df\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncate\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001B[39m, in \u001B[36mDataFrame.show\u001B[39m\u001B[34m(self, n, truncate, vertical)\u001B[39m\n\u001B[32m    887\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mshow\u001B[39m(\u001B[38;5;28mself\u001B[39m, n: \u001B[38;5;28mint\u001B[39m = \u001B[32m20\u001B[39m, truncate: Union[\u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mint\u001B[39m] = \u001B[38;5;28;01mTrue\u001B[39;00m, vertical: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    888\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Prints the first ``n`` rows to the console.\u001B[39;00m\n\u001B[32m    889\u001B[39m \n\u001B[32m    890\u001B[39m \u001B[33;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    945\u001B[39m \u001B[33;03m    name | Bob\u001B[39;00m\n\u001B[32m    946\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m947\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_show_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:978\u001B[39m, in \u001B[36mDataFrame._show_string\u001B[39m\u001B[34m(self, n, truncate, vertical)\u001B[39m\n\u001B[32m    969\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[32m    970\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[32m    971\u001B[39m         error_class=\u001B[33m\"\u001B[39m\u001B[33mNOT_BOOL\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    972\u001B[39m         message_parameters={\n\u001B[32m   (...)\u001B[39m\u001B[32m    975\u001B[39m         },\n\u001B[32m    976\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m978\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_jdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshowString\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mint_truncate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001B[39m, in \u001B[36mJavaMember.__call__\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m   1316\u001B[39m command = proto.CALL_COMMAND_NAME +\\\n\u001B[32m   1317\u001B[39m     \u001B[38;5;28mself\u001B[39m.command_header +\\\n\u001B[32m   1318\u001B[39m     args_command +\\\n\u001B[32m   1319\u001B[39m     proto.END_COMMAND_PART\n\u001B[32m   1321\u001B[39m answer = \u001B[38;5;28mself\u001B[39m.gateway_client.send_command(command)\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m return_value = \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1323\u001B[39m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1325\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[32m   1326\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[33m\"\u001B[39m\u001B[33m_detach\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001B[39m, in \u001B[36mcapture_sql_exception.<locals>.deco\u001B[39m\u001B[34m(*a, **kw)\u001B[39m\n\u001B[32m    181\u001B[39m converted = convert_exception(e.java_exception)\n\u001B[32m    182\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[32m    183\u001B[39m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[32m    184\u001B[39m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m185\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    186\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    187\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[31mAnalysisException\u001B[39m: Since Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\nreferenced columns only include the internal corrupt record column\n(named _corrupt_record by default). For example:\nspark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\nand spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\nInstead, you can cache or save the parsed results and then send the same query.\nFor example, val df = spark.read.schema(schema).csv(file).cache() and then\ndf.filter($\"_corrupt_record\".isNotNull).count()."
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 2 MAKE DIMENSION TABLES AVAILABLE AS VIEWS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dim_date = spark.read.format(\"delta\").load(\"spark-warehouse/dimdate\")\n",
    "dim_vehicle = spark.read.format(\"delta\").load(\"spark-warehouse/dimvehicle\")\n",
    "dim_user = spark.read.format(\"delta\").load(\"spark-warehouse/dimuser\")\n",
    "dim_weather = spark.read.format(\"delta\").load(\"spark-warehouse/dimuser\")\n",
    "dim_lock = spark.read.format(\"delta\").load(\"spark-warehouse/dimlock\")\n",
    "\n",
    "dim_date.createOrReplaceTempView(\"dimDate\")\n",
    "dim_user.createOrReplaceTempView(\"dimUser\")\n",
    "dim_vehicle.createOrReplaceTempView(\"dimVehicle\")\n",
    "dim_weather.createOrReplaceTempView(\"dimWeather\")\n",
    "dim_lock.createOrReplaceTempView(\"dimLock\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T12:52:27.961978Z",
     "start_time": "2025-03-19T12:52:14.235742Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o82.load.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (DESKTOP-DJQSI3S executor driver): org.apache.spark.SparkException: Encountered error while reading file file:///C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000001.json. Details:\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFilesError(QueryExecutionErrors.scala:864)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:293)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000001.json at 0 exp: 1773210490 got: -726966649\r\n\tat org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)\r\n\tat java.base/java.io.DataInputStream.read(DataInputStream.java:151)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\r\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)\r\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:158)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:198)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:67)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\t... 22 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4334)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3575)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4324)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3575)\r\n\tat org.apache.spark.sql.delta.Snapshot.protocolMetadataAndICTReconstruction(Snapshot.scala:309)\r\n\tat org.apache.spark.sql.delta.Snapshot._reconstructedProtocolMetadataAndICT$lzycompute(Snapshot.scala:203)\r\n\tat org.apache.spark.sql.delta.Snapshot._reconstructedProtocolMetadataAndICT(Snapshot.scala:196)\r\n\tat org.apache.spark.sql.delta.Snapshot.metadata(Snapshot.scala:278)\r\n\tat org.apache.spark.sql.delta.managedcommit.CommitOwnerProvider$.getTableCommitOwner(CommitOwnerClient.scala:212)\r\n\tat org.apache.spark.sql.delta.Snapshot.initializeTableCommitOwner(Snapshot.scala:237)\r\n\tat org.apache.spark.sql.delta.Snapshot.<init>(Snapshot.scala:235)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$createSnapshot$2(SnapshotManagement.scala:634)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment(SnapshotManagement.scala:796)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment$(SnapshotManagement.scala:782)\r\n\tat org.apache.spark.sql.delta.DeltaLog.createSnapshotFromGivenOrEquivalentLogSegment(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshot(SnapshotManagement.scala:627)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshot$(SnapshotManagement.scala:618)\r\n\tat org.apache.spark.sql.delta.DeltaLog.createSnapshot(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotForLogSegmentInternal$1(SnapshotManagement.scala:1043)\r\n\tat scala.Option.map(Option.scala:230)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal(SnapshotManagement.scala:1036)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal$(SnapshotManagement.scala:1031)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotForLogSegmentInternal(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot(SnapshotManagement.scala:1012)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot$(SnapshotManagement.scala:1003)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getUpdatedSnapshot(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$2(SnapshotManagement.scala:583)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.DeltaLog.recordFrameProfile(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$1(SnapshotManagement.scala:573)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly(SnapshotManagement.scala:78)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly$(SnapshotManagement.scala:75)\r\n\tat org.apache.spark.sql.delta.DeltaLog.withSnapshotLockInterruptibly(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit(SnapshotManagement.scala:573)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit$(SnapshotManagement.scala:572)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotAtInit(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$init$(SnapshotManagement.scala:69)\r\n\tat org.apache.spark.sql.delta.DeltaLog.<init>(DeltaLog.scala:80)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$4(DeltaLog.scala:853)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$3(DeltaLog.scala:848)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordFrameProfile(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:136)\r\n\tat com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)\r\n\tat com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordOperation(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:135)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:125)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:115)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordDeltaOperation(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.createDeltaLog$1(DeltaLog.scala:847)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$5(DeltaLog.scala:866)\r\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4792)\r\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)\r\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)\r\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)\r\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2257)\r\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:4000)\r\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4789)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.getDeltaLogFromCache$1(DeltaLog.scala:865)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.apply(DeltaLog.scala:875)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.forTable(DeltaLog.scala:751)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$deltaLog$1(DeltaTableV2.scala:92)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog$lzycompute(DeltaTableV2.scala:92)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog(DeltaTableV2.scala:90)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$4(DeltaTableV2.scala:145)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$1(DeltaTableV2.scala:145)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot$lzycompute(DeltaTableV2.scala:144)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot(DeltaTableV2.scala:124)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation$lzycompute(DeltaTableV2.scala:236)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation(DeltaTableV2.scala:234)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.$anonfun$createRelation$5(DeltaDataSource.scala:250)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.recordFrameProfile(DeltaDataSource.scala:49)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:209)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.spark.SparkException: Encountered error while reading file file:///C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000001.json. Details:\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFilesError(QueryExecutionErrors.scala:864)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:293)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000001.json at 0 exp: 1773210490 got: -726966649\r\n\tat org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)\r\n\tat java.base/java.io.DataInputStream.read(DataInputStream.java:151)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\r\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)\r\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:158)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:198)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:67)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\t... 22 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPy4JJavaError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m dim_date = \u001B[43mspark\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m.\u001B[49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdelta\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mspark-warehouse/dimdate\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m dim_vehicle = spark.read.format(\u001B[33m\"\u001B[39m\u001B[33mdelta\u001B[39m\u001B[33m\"\u001B[39m).load(\u001B[33m\"\u001B[39m\u001B[33mspark-warehouse/dimvehicle\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      3\u001B[39m dim_user = spark.read.format(\u001B[33m\"\u001B[39m\u001B[33mdelta\u001B[39m\u001B[33m\"\u001B[39m).load(\u001B[33m\"\u001B[39m\u001B[33mspark-warehouse/dimuser\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:307\u001B[39m, in \u001B[36mDataFrameReader.load\u001B[39m\u001B[34m(self, path, format, schema, **options)\u001B[39m\n\u001B[32m    305\u001B[39m \u001B[38;5;28mself\u001B[39m.options(**options)\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m307\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_jreader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    308\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    309\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(path) != \u001B[38;5;28mlist\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001B[39m, in \u001B[36mJavaMember.__call__\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m   1316\u001B[39m command = proto.CALL_COMMAND_NAME +\\\n\u001B[32m   1317\u001B[39m     \u001B[38;5;28mself\u001B[39m.command_header +\\\n\u001B[32m   1318\u001B[39m     args_command +\\\n\u001B[32m   1319\u001B[39m     proto.END_COMMAND_PART\n\u001B[32m   1321\u001B[39m answer = \u001B[38;5;28mself\u001B[39m.gateway_client.send_command(command)\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m return_value = \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1323\u001B[39m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1325\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[32m   1326\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[33m\"\u001B[39m\u001B[33m_detach\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001B[39m, in \u001B[36mcapture_sql_exception.<locals>.deco\u001B[39m\u001B[34m(*a, **kw)\u001B[39m\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdeco\u001B[39m(*a: Any, **kw: Any) -> Any:\n\u001B[32m    178\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    180\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    181\u001B[39m         converted = convert_exception(e.java_exception)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\data4_project_group5\\myvenv\\Lib\\site-packages\\py4j\\protocol.py:326\u001B[39m, in \u001B[36mget_return_value\u001B[39m\u001B[34m(answer, gateway_client, target_id, name)\u001B[39m\n\u001B[32m    324\u001B[39m value = OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[32m2\u001B[39m:], gateway_client)\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[32m1\u001B[39m] == REFERENCE_TYPE:\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[32m    327\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.\n\u001B[32m    328\u001B[39m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m, name), value)\n\u001B[32m    329\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    330\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[32m    331\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.\n\u001B[32m    332\u001B[39m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m, name, value))\n",
      "\u001B[31mPy4JJavaError\u001B[39m: An error occurred while calling o82.load.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1) (DESKTOP-DJQSI3S executor driver): org.apache.spark.SparkException: Encountered error while reading file file:///C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000001.json. Details:\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFilesError(QueryExecutionErrors.scala:864)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:293)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000001.json at 0 exp: 1773210490 got: -726966649\r\n\tat org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)\r\n\tat java.base/java.io.DataInputStream.read(DataInputStream.java:151)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\r\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)\r\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:158)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:198)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:67)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\t... 22 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4334)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3575)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4324)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3575)\r\n\tat org.apache.spark.sql.delta.Snapshot.protocolMetadataAndICTReconstruction(Snapshot.scala:309)\r\n\tat org.apache.spark.sql.delta.Snapshot._reconstructedProtocolMetadataAndICT$lzycompute(Snapshot.scala:203)\r\n\tat org.apache.spark.sql.delta.Snapshot._reconstructedProtocolMetadataAndICT(Snapshot.scala:196)\r\n\tat org.apache.spark.sql.delta.Snapshot.metadata(Snapshot.scala:278)\r\n\tat org.apache.spark.sql.delta.managedcommit.CommitOwnerProvider$.getTableCommitOwner(CommitOwnerClient.scala:212)\r\n\tat org.apache.spark.sql.delta.Snapshot.initializeTableCommitOwner(Snapshot.scala:237)\r\n\tat org.apache.spark.sql.delta.Snapshot.<init>(Snapshot.scala:235)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$createSnapshot$2(SnapshotManagement.scala:634)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment(SnapshotManagement.scala:796)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment$(SnapshotManagement.scala:782)\r\n\tat org.apache.spark.sql.delta.DeltaLog.createSnapshotFromGivenOrEquivalentLogSegment(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshot(SnapshotManagement.scala:627)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.createSnapshot$(SnapshotManagement.scala:618)\r\n\tat org.apache.spark.sql.delta.DeltaLog.createSnapshot(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotForLogSegmentInternal$1(SnapshotManagement.scala:1043)\r\n\tat scala.Option.map(Option.scala:230)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal(SnapshotManagement.scala:1036)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal$(SnapshotManagement.scala:1031)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotForLogSegmentInternal(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot(SnapshotManagement.scala:1012)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot$(SnapshotManagement.scala:1003)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getUpdatedSnapshot(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$2(SnapshotManagement.scala:583)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.DeltaLog.recordFrameProfile(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$1(SnapshotManagement.scala:573)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly(SnapshotManagement.scala:78)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly$(SnapshotManagement.scala:75)\r\n\tat org.apache.spark.sql.delta.DeltaLog.withSnapshotLockInterruptibly(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit(SnapshotManagement.scala:573)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit$(SnapshotManagement.scala:572)\r\n\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotAtInit(DeltaLog.scala:74)\r\n\tat org.apache.spark.sql.delta.SnapshotManagement.$init$(SnapshotManagement.scala:69)\r\n\tat org.apache.spark.sql.delta.DeltaLog.<init>(DeltaLog.scala:80)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$4(DeltaLog.scala:853)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$3(DeltaLog.scala:848)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordFrameProfile(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:136)\r\n\tat com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)\r\n\tat com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordOperation(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:135)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:125)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:115)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.recordDeltaOperation(DeltaLog.scala:651)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.createDeltaLog$1(DeltaLog.scala:847)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$5(DeltaLog.scala:866)\r\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4792)\r\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)\r\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)\r\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)\r\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2257)\r\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:4000)\r\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4789)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.getDeltaLogFromCache$1(DeltaLog.scala:865)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.apply(DeltaLog.scala:875)\r\n\tat org.apache.spark.sql.delta.DeltaLog$.forTable(DeltaLog.scala:751)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$deltaLog$1(DeltaTableV2.scala:92)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog$lzycompute(DeltaTableV2.scala:92)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog(DeltaTableV2.scala:90)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$4(DeltaTableV2.scala:145)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$1(DeltaTableV2.scala:145)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot$lzycompute(DeltaTableV2.scala:144)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot(DeltaTableV2.scala:124)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation$lzycompute(DeltaTableV2.scala:236)\r\n\tat org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation(DeltaTableV2.scala:234)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.$anonfun$createRelation$5(DeltaDataSource.scala:250)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\r\n\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.recordFrameProfile(DeltaDataSource.scala:49)\r\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:209)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: org.apache.spark.SparkException: Encountered error while reading file file:///C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000001.json. Details:\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.cannotReadFilesError(QueryExecutionErrors.scala:864)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:293)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/C:/Users/kkiva/data4_project_group5/examples/spark-warehouse/dimdate/_delta_log/00000000000000000001.json at 0 exp: 1773210490 got: -726966649\r\n\tat org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:347)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:303)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:252)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:197)\r\n\tat java.base/java.io.DataInputStream.read(DataInputStream.java:151)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)\r\n\tat org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227)\r\n\tat org.apache.hadoop.util.LineReader.readLine(LineReader.java:185)\r\n\tat org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:158)\r\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:198)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:67)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\t... 22 more\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 3 Build the fact table\n",
    "\n",
    "Within the creation of a fact table always perform these two tasks:\n",
    "1.   Include the measures of the fact\n",
    "2. Use the dimension tables to look up the surrogate keys that correspond with the natural key value. In case of SCD2 dimension use the scd_start en scd_end to find the correct version of the data in the dimension\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------------+--------+----------+--------------------+\n",
      "|OrderID|dateSK|          salesrepSK|count_mv|revenue_mv|                 md5|\n",
      "+-------+------+--------------------+--------+----------+--------------------+\n",
      "|      1|   650|b65df3d9-20dc-42d...|       1| 851804379|a237b06f2932af7dd...|\n",
      "|      2|  1369|b65df3d9-20dc-42d...|       1| 683057055|f2f29b4c68d66f8a6...|\n",
      "|      3|   920|b65df3d9-20dc-42d...|       1|1732115679|ce49bc85950b1de43...|\n",
      "|      4|   604|b65df3d9-20dc-42d...|       1|1275042249|908be3f822ea3717d...|\n",
      "|      5|   897|b65df3d9-20dc-42d...|       1| 694153767|fddeb9cfa84ec3a43...|\n",
      "|      6|   812|b65df3d9-20dc-42d...|       1|1959464599|4c7a00e21fb76c7d8...|\n",
      "|      7|   421|b65df3d9-20dc-42d...|       1|1170677605|31eb59a94c0a895e2...|\n",
      "|      8|   691|b65df3d9-20dc-42d...|       1|1588502393|a30a88ea5f72f4df0...|\n",
      "|      9|  1254|b65df3d9-20dc-42d...|       1|1173163372|01aeb05aafe965913...|\n",
      "|     10|  1311|b65df3d9-20dc-42d...|       1| 788682390|b0f5e545ae3941ff0...|\n",
      "+-------+------+--------------------+--------+----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "ride_src_df.createOrReplaceTempView(\"rides_source\")\n",
    "ridesFactFromSource = spark.sql(\"select src.rideid as ride_id, du.userSK as user_sk, src.startlockid as start_lock_ic, src.endlockid as end_lock_id, dd.date_sk as date_sk,dv.vehicleid as vehicle_id,(src.endtime - src.startime) as ride_duration, md5(concat(src.rideid, du.userSK, src.startlockid, src.endlockid, dd.date_sk, dv.vehicleid)) as md5 \\\n",
    "          from rides_source as src \\\n",
    "          left outer join subscriptions_df as sub on src.subscriptionid = sub.subscriptionid \\\n",
    "          left outer join dim_user as du on sub.userid = du.userSK \\\n",
    "          left outer join dim_lock as dl on src.startlockid = dl.lockid and src.endlockid = dl.lockid  \\\n",
    "          left outer join dim_date as dd on DATE(src.starttime) = dd.CalendarDate \\\n",
    "          left outer join dim_vehicle as dv on src.vehicleid = dv.vehicleid \\\n",
    "\")\n",
    "\n",
    "ridesFactFromSource.show(10)\n",
    "ridesFactFromSource.createOrReplaceTempView(\"factRides_new\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T09:49:10.184840500Z",
     "start_time": "2024-09-10T09:48:52.004507500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial load\n",
    "The first time loading the fact table perform a FULL load. All data is written to the Delta Table.\n",
    "After initial load the code line has to be disabled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "ridesFactFromSource.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"factRides\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T09:49:24.830124800Z",
     "start_time": "2024-09-10T09:49:10.188063700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Incremental load\n",
    "When previous runs where performend you can opt for a 'faster' incremental run that only writes away changes. UPDATES and INSERTS are performed in one run.\n",
    "In our solution we use an md5 based on all fields in the source table to detect changes. This is not the most efficient way to detect changes. A better way is to use a timestamp field in the source table and use that to detect changes. This is not implemented in this example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|                0|               0|               0|                0|\n",
      "+-----------------+----------------+----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "dt_factRides = DeltaTable.forPath(spark,\".\\spark-warehouse\\\\factrides\")\n",
    "dt_factRides.toDF().createOrReplaceTempView(\"factRides_current\")\n",
    "#Merge to perform updates (TODO: Implement md5 strategy)\n",
    "\n",
    "result = spark.sql(\"MERGE INTO factRides_current AS target \\\n",
    "      using factRides_new AS source ON target.rideID = source.rideID \\\n",
    "      WHEN MATCHED and source.MD5<>target.MD5 THEN UPDATE SET * \\\n",
    "      WHEN NOT MATCHED THEN INSERT *\")\n",
    "\n",
    "result.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T09:49:36.248336800Z",
     "start_time": "2024-09-10T09:49:24.834540600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     999|\n",
      "+--------+\n",
      "\n",
      "+-------+------+--------------------+--------+----------+--------------------+\n",
      "|OrderID|dateSK|          salesrepSK|count_mv|revenue_mv|                 md5|\n",
      "+-------+------+--------------------+--------+----------+--------------------+\n",
      "|      1|   650|b65df3d9-20dc-42d...|       1| 851804379|a237b06f2932af7dd...|\n",
      "+-------+------+--------------------+--------+----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: ALWAYS TEST THE CREATED CODE.\n",
    "# In this example I changed order 498 in the operational database and checked the change after the run.\n",
    "# spark.sql(\"select * from factsales f join dimsalesrep ds on f.salesrepSK = ds.salesrepSK where OrderID = 192  \").show()\n",
    "spark.sql(\"select count(*) from factrides\").show()\n",
    "spark.sql(\"select * from factrides where rideId=1\").show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T09:49:41.411568200Z",
     "start_time": "2024-09-10T09:49:36.262239400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking the history of your delta fact table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# The history information is derived from the delta table log files. They contain a lot of information of all the actions performed on the table. In this case it tells us something about de merge operations. You can find statistics about the update and insert counts in the document.\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mfact\u001B[49m\u001B[38;5;241m.\u001B[39mhistory()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m10\u001B[39m,\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'fact' is not defined"
     ]
    }
   ],
   "source": [
    "# The history information is derived from the delta table log files. They contain a lot of information of all the actions performed on the table. In this case it tells us something about de merge operations. You can find statistics about the update and insert counts in the document.\n",
    "\n",
    "fact.history().show(10,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T09:49:42.067046800Z",
     "start_time": "2024-09-10T09:49:41.415008600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T11:02:02.240620Z",
     "start_time": "2025-03-19T11:01:55.677763Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
